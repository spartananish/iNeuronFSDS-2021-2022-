{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8877a3c9",
   "metadata": {},
   "source": [
    "1. Explain convolutional neural network, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbcde8f",
   "metadata": {},
   "source": [
    "Answer->CNN (Convolutional Neural Network or ConvNet) is a type of feed-forward artificial network where the connectivity pattern between its neurons is inspired by the organization of the animal visual cortex. The visual cortex has a small region of cells that are sensitive to specific regions of the visual field."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801c4acb",
   "metadata": {},
   "source": [
    "2. How does refactoring parts of your neural network definition favor you ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5792458",
   "metadata": {},
   "source": [
    "Answer:- Refactoring or Code Refactoring is defined as systematic process of improving existing computer code, without adding new functionality or changing external behaviour of the code. It is intended to change the implementation, definition, structure of code without changing functionality of software. It improves extensibility, maintainability, and readability of software without changing what it actually does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcca592",
   "metadata": {},
   "source": [
    "3. What does it mean to flatten? Is it necessary to include it in the MNIST CNN? What is the reason\n",
    "for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b405c03",
   "metadata": {},
   "source": [
    "Answer:- flatten function flattens the multi-dimensional input tensors into a single dimension, so you can model your input layer and build your neural network model, then pass those data into every single neuron of the model effectively. You can understand this easily with the fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afc1ad5",
   "metadata": {},
   "source": [
    "4. What exactly does NCHW stand for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4384ba",
   "metadata": {},
   "source": [
    "Answer: NCHW stands for: batch N, channels C, depth D, height H, width W. It is a way to store multidimensional arrays / data frames / matrix into memory, which can be considered as a 1-D array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff83535",
   "metadata": {},
   "source": [
    "5.Explain definition of receptive field?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfc8012",
   "metadata": {},
   "source": [
    "Answer->Receptive fields are defined portion of space or spatial construct containing units that provide input to a set of units within a corresponding layer. The receptive field is defined by the filter size of a layer within a convolution neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f7bb64",
   "metadata": {},
   "source": [
    "6. What is the scale of an activation&#39;s receptive field after two stride-2 convolutions? What is the\n",
    "reason for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988663de",
   "metadata": {},
   "source": [
    "Answer->While deep neural networks have overwhelmingly established state-of-the-art results in many artificial intelligence problems, they can still be difficult to develop and debug. Recent research on deep learning understanding has focused on feature visualization \n",
    "[1, 2]\n",
    ", theoretical guarantees \n",
    "[3, 4]\n",
    ", model interpretability \n",
    "[5, 6]\n",
    ", and generalization \n",
    "[7, 8]\n",
    ".\n",
    "\n",
    "In this work, we analyze deep neural networks from a complementary perspective, focusing on convolutional models. We are interested in understanding the extent to which input signals may affect output features, and mapping features at any part of the network to the region in the input that produces them. The key parameter to associate an output feature to an input region is the receptive field of the convolutional network, which is defined as the size of the region in the input that produces the feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f4e204",
   "metadata": {},
   "source": [
    "7. What is the tensor representation of a color image?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41754bc9",
   "metadata": {},
   "source": [
    "Answer: The representation of an image can take many forms. Most of the time, it refers to the way that the conveyed information, such as color, is coded digitally and how the image is stored, i.e., how is structured an image file. Several open or patented standards were proposed to create, manipulate, store and exchange digital images. They describe the format of image files, the algorithms of image encoding such as compression as well as the format of additional information often called metadata.\n",
    "\n",
    "TENSORS IMAGES\n",
    "Tensors can be understood as nested lists of objects of the previous order all with the same size. For example, an order three tensor can be thought of as a list of matrices all of which have the same number of rows and columns. These matrices are tensors of order two and since they have all the same number of rows and columns, the tensor of order three is actually like a cuboid of numbers and we can find numbers by going along any of the three-axis. Each number is identified by the row, the column, and the depth at which itâ€™s stored. We can formalize this idea in the concept of shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a19731",
   "metadata": {},
   "source": [
    "8. How does a color input interact with a convolution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7611b7fc",
   "metadata": {},
   "source": [
    "\n",
    "Answer->The invariance of the CNN to an artifact is derived from the data.\n",
    "\n",
    "The CNN only has the data to learn if color is a decisive factor for recognizing an object or not. If you only present it with red 'A's, it will learn that red is a decisive factor for recognizing the 'A'. By presenting it with a large number of different 'A's that are colored differently. The CNN will learn that color has little influence in recognizing an 'A'. The weight of the red channels or red features will not be dominant. You might even find that the CNN will learn grayscale filters instead of color sensitive filters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
